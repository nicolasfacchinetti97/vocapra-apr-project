{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d0fe4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# data preaparation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# dealing with images\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# for writing the models\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "# metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83f1e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc09b928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>segment</th>\n",
       "      <th>label</th>\n",
       "      <th>samplingrate</th>\n",
       "      <th>ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./Labelled/Bleatings/evt_000_000_000681_210415...</td>\n",
       "      <td>0</td>\n",
       "      <td>Bleatings</td>\n",
       "      <td>16000</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./Labelled/Bleatings/evt_000_000_000681_210415...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bleatings</td>\n",
       "      <td>16000</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./Labelled/Bleatings/evt_000_000_000681_210415...</td>\n",
       "      <td>2</td>\n",
       "      <td>Bleatings</td>\n",
       "      <td>16000</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./Labelled/Bleatings/evt_000_000_000681_210415...</td>\n",
       "      <td>3</td>\n",
       "      <td>Bleatings</td>\n",
       "      <td>16000</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./Labelled/Bleatings/evt_000_000_000681_210415...</td>\n",
       "      <td>4</td>\n",
       "      <td>Bleatings</td>\n",
       "      <td>16000</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  segment      label  \\\n",
       "0  ./Labelled/Bleatings/evt_000_000_000681_210415...        0  Bleatings   \n",
       "1  ./Labelled/Bleatings/evt_000_000_000681_210415...        1  Bleatings   \n",
       "2  ./Labelled/Bleatings/evt_000_000_000681_210415...        2  Bleatings   \n",
       "3  ./Labelled/Bleatings/evt_000_000_000681_210415...        3  Bleatings   \n",
       "4  ./Labelled/Bleatings/evt_000_000_000681_210415...        4  Bleatings   \n",
       "\n",
       "   samplingrate      ms  \n",
       "0         16000  3000.0  \n",
       "1         16000  3000.0  \n",
       "2         16000  3000.0  \n",
       "3         16000  3000.0  \n",
       "4         16000  3000.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv(\"processed_metadata.csv\")\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e55519",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network on log Mel-spectrogram images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fbc140a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5312 images belonging to 3 classes.\n",
      "Found 1327 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "path_dir = \"./img_data\"\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    validation_split = 0.2)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    path_dir,\n",
    "    target_size=(128,94),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    path_dir,\n",
    "    target_size=(128,94),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dce0021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, InputLayer, BatchNormalization, Dropout, AveragePooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626f21c4",
   "metadata": {},
   "source": [
    "## First CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9425b0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_52 (Conv2D)           (None, 63, 46, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 31, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 16, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 8, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 8, 6, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 4, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 128)               196736    \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 298,435\n",
      "Trainable params: 298,435\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "input_shape=(128, 94, 3)\n",
    "\n",
    "#1st hidden layer\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', strides=(2, 2), input_shape=input_shape))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "#2nd hidden layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', strides=(2, 2), padding=\"same\"))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "#3rd hidden layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "#ANN\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate=0.5))#Add fully connected layer.\n",
    "model.add(Dense(units = 128, activation='relu'))\n",
    "model.add(Dense(units = 64, activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "#Output layer\n",
    "model.add(Dense(units= 3, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "908b2449",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "205bbafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "166/166 [==============================] - 51s 305ms/step - loss: 0.6132 - accuracy: 0.7331\n",
      "Epoch 2/50\n",
      "166/166 [==============================] - 21s 125ms/step - loss: 0.4296 - accuracy: 0.8144\n",
      "Epoch 3/50\n",
      "166/166 [==============================] - 21s 126ms/step - loss: 0.3838 - accuracy: 0.8355\n",
      "Epoch 4/50\n",
      "166/166 [==============================] - 21s 125ms/step - loss: 0.3666 - accuracy: 0.8358\n",
      "Epoch 5/50\n",
      "166/166 [==============================] - 22s 130ms/step - loss: 0.3341 - accuracy: 0.8596\n",
      "Epoch 6/50\n",
      "166/166 [==============================] - 22s 130ms/step - loss: 0.3208 - accuracy: 0.8577\n",
      "Epoch 7/50\n",
      "166/166 [==============================] - 21s 128ms/step - loss: 0.3099 - accuracy: 0.8656\n",
      "Epoch 8/50\n",
      "166/166 [==============================] - 21s 129ms/step - loss: 0.2970 - accuracy: 0.8741\n",
      "Epoch 9/50\n",
      "166/166 [==============================] - 21s 129ms/step - loss: 0.2888 - accuracy: 0.8735\n",
      "Epoch 10/50\n",
      "166/166 [==============================] - 21s 129ms/step - loss: 0.2785 - accuracy: 0.8803\n",
      "Epoch 11/50\n",
      "166/166 [==============================] - 21s 129ms/step - loss: 0.2671 - accuracy: 0.8902\n",
      "Epoch 12/50\n",
      "166/166 [==============================] - 22s 130ms/step - loss: 0.2540 - accuracy: 0.8914\n",
      "Epoch 13/50\n",
      "166/166 [==============================] - 21s 129ms/step - loss: 0.2388 - accuracy: 0.9008\n",
      "Epoch 14/50\n",
      "166/166 [==============================] - 22s 131ms/step - loss: 0.2334 - accuracy: 0.8998\n",
      "Epoch 15/50\n",
      "166/166 [==============================] - 21s 129ms/step - loss: 0.2157 - accuracy: 0.9068\n",
      "Epoch 16/50\n",
      "166/166 [==============================] - 22s 130ms/step - loss: 0.2153 - accuracy: 0.9068\n",
      "Epoch 17/50\n",
      "166/166 [==============================] - 22s 130ms/step - loss: 0.1924 - accuracy: 0.9196\n",
      "Epoch 18/50\n",
      "166/166 [==============================] - 21s 129ms/step - loss: 0.1982 - accuracy: 0.9123\n",
      "Epoch 19/50\n",
      "166/166 [==============================] - 22s 131ms/step - loss: 0.1753 - accuracy: 0.9249\n",
      "Epoch 20/50\n",
      "166/166 [==============================] - 22s 132ms/step - loss: 0.1651 - accuracy: 0.9298\n",
      "Epoch 21/50\n",
      "166/166 [==============================] - 22s 131ms/step - loss: 0.1536 - accuracy: 0.9384\n",
      "Epoch 22/50\n",
      "166/166 [==============================] - 22s 131ms/step - loss: 0.1429 - accuracy: 0.9454\n",
      "Epoch 23/50\n",
      "166/166 [==============================] - 22s 131ms/step - loss: 0.1355 - accuracy: 0.9448\n",
      "Epoch 24/50\n",
      "166/166 [==============================] - 21s 124ms/step - loss: 0.1103 - accuracy: 0.9544\n",
      "Epoch 25/50\n",
      "166/166 [==============================] - 21s 127ms/step - loss: 0.1104 - accuracy: 0.9563\n",
      "Epoch 26/50\n",
      "166/166 [==============================] - 21s 126ms/step - loss: 0.0842 - accuracy: 0.9684\n",
      "Epoch 27/50\n",
      "166/166 [==============================] - 21s 126ms/step - loss: 0.1025 - accuracy: 0.9607\n",
      "Epoch 28/50\n",
      "166/166 [==============================] - 21s 125ms/step - loss: 0.0890 - accuracy: 0.9663\n",
      "Epoch 29/50\n",
      "166/166 [==============================] - 21s 125ms/step - loss: 0.0937 - accuracy: 0.9623\n",
      "Epoch 30/50\n",
      "166/166 [==============================] - 21s 125ms/step - loss: 0.0814 - accuracy: 0.9708\n",
      "Epoch 31/50\n",
      "166/166 [==============================] - 21s 128ms/step - loss: 0.0605 - accuracy: 0.9765\n",
      "Epoch 32/50\n",
      "166/166 [==============================] - 21s 126ms/step - loss: 0.0610 - accuracy: 0.9757\n",
      "Epoch 33/50\n",
      "166/166 [==============================] - 21s 126ms/step - loss: 0.0678 - accuracy: 0.9776\n",
      "Epoch 34/50\n",
      "166/166 [==============================] - 21s 124ms/step - loss: 0.0671 - accuracy: 0.9721\n",
      "Epoch 35/50\n",
      "166/166 [==============================] - 21s 127ms/step - loss: 0.0557 - accuracy: 0.9770\n",
      "Epoch 36/50\n",
      "166/166 [==============================] - 21s 127ms/step - loss: 0.0567 - accuracy: 0.9787\n",
      "Epoch 37/50\n",
      "166/166 [==============================] - 21s 126ms/step - loss: 0.0409 - accuracy: 0.9859\n",
      "Epoch 38/50\n",
      "166/166 [==============================] - 21s 127ms/step - loss: 0.0591 - accuracy: 0.9772\n",
      "Epoch 39/50\n",
      "166/166 [==============================] - 21s 127ms/step - loss: 0.0566 - accuracy: 0.9814\n",
      "Epoch 40/50\n",
      "166/166 [==============================] - 21s 124ms/step - loss: 0.0300 - accuracy: 0.9900\n",
      "Epoch 41/50\n",
      "166/166 [==============================] - 21s 127ms/step - loss: 0.0419 - accuracy: 0.9855\n",
      "Epoch 42/50\n",
      "166/166 [==============================] - 21s 128ms/step - loss: 0.0506 - accuracy: 0.9819\n",
      "Epoch 43/50\n",
      "166/166 [==============================] - 21s 126ms/step - loss: 0.0490 - accuracy: 0.9804\n",
      "Epoch 44/50\n",
      "166/166 [==============================] - 21s 127ms/step - loss: 0.0384 - accuracy: 0.9859\n",
      "Epoch 45/50\n",
      "166/166 [==============================] - 21s 126ms/step - loss: 0.0364 - accuracy: 0.9861\n",
      "Epoch 46/50\n",
      "166/166 [==============================] - 21s 126ms/step - loss: 0.0347 - accuracy: 0.9889\n",
      "Epoch 47/50\n",
      "166/166 [==============================] - 21s 127ms/step - loss: 0.0387 - accuracy: 0.9866\n",
      "Epoch 48/50\n",
      "166/166 [==============================] - 21s 127ms/step - loss: 0.0427 - accuracy: 0.9819\n",
      "Epoch 49/50\n",
      "166/166 [==============================] - 21s 126ms/step - loss: 0.0294 - accuracy: 0.9889\n",
      "Epoch 50/50\n",
      "166/166 [==============================] - 21s 125ms/step - loss: 0.0354 - accuracy: 0.9891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24cab825160>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d22420d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 4s 92ms/step - loss: 0.8039 - accuracy: 0.8772\n",
      "n Test_Accuracy: [0.8038811087608337, 0.8771665692329407]\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = model.evaluate(validation_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0beabcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[677   0   0]\n",
      " [  0 117   0]\n",
      " [  0   0 533]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model.predict(validation_generator)\n",
    "y_pred = np.argmax(pred, axis=1)\n",
    "y_true = np.argmax(pred, axis=1)\n",
    "print('confusion matrix')\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "    #confusion matrix\n",
    "f, ax = plt.subplots(figsize=(8,5))\n",
    "sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt=\".0f\", ax=ax)\n",
    "plt.xlabel(\"y_pred\")\n",
    "plt.ylabel(\"y_true\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af6869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graphing our training and validation\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, ‘r’, label=’Training acc’)\n",
    "plt.plot(epochs, val_acc, ‘b’, label=’Validation acc’)\n",
    "plt.title(‘Training and validation accuracy’)\n",
    "plt.ylabel(‘accuracy’) \n",
    "plt.xlabel(‘epoch’)\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, ‘r’, label=’Training loss’)\n",
    "plt.plot(epochs, val_loss, ‘b’, label=’Validation loss’)\n",
    "plt.title(‘Training and validation loss’)\n",
    "plt.ylabel(‘loss’) \n",
    "plt.xlabel(‘epoch’)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d442a2b",
   "metadata": {},
   "source": [
    "## Second CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "245d0787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_55 (Conv2D)           (None, 128, 94, 25)       1900      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 64, 47, 25)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 32, 24, 50)        31300     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 16, 12, 50)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 12, 50)        200       \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 8, 6, 70)          31570     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 4, 3, 70)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4, 3, 70)          280       \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 840)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 100)               84100     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 154,553\n",
      "Trainable params: 154,313\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build a sequential model\n",
    "model1 = Sequential()\n",
    "model1.add(InputLayer(input_shape=(128, 94, 3)))\n",
    "\n",
    "# 1st conv block\n",
    "model1.add(Conv2D(25, (5, 5), activation='relu', strides=(1, 1), padding='same'))\n",
    "model1.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "# 2nd conv block\n",
    "model1.add(Conv2D(50, (5, 5), activation='relu', strides=(2, 2), padding='same'))\n",
    "model1.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "model1.add(BatchNormalization())\n",
    "# 3rd conv block\n",
    "model1.add(Conv2D(70, (3, 3), activation='relu', strides=(2, 2), padding='same'))\n",
    "model1.add(MaxPool2D(pool_size=(2, 2), padding='valid'))\n",
    "model1.add(BatchNormalization())\n",
    "# ANN block\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(units=100, activation='relu'))\n",
    "model1.add(Dense(units=50, activation='relu'))\n",
    "model1.add(Dropout(0.25))\n",
    "# output layer\n",
    "model1.add(Dense(units=3, activation='softmax'))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8fe76f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "166/166 [==============================] - 41s 247ms/step - loss: 0.5358 - accuracy: 0.7673\n",
      "Epoch 2/50\n",
      "166/166 [==============================] - 43s 261ms/step - loss: 0.3948 - accuracy: 0.8357\n",
      "Epoch 3/50\n",
      "166/166 [==============================] - 44s 264ms/step - loss: 0.3613 - accuracy: 0.8477\n",
      "Epoch 4/50\n",
      "166/166 [==============================] - 44s 266ms/step - loss: 0.3185 - accuracy: 0.8607\n",
      "Epoch 5/50\n",
      "166/166 [==============================] - 43s 262ms/step - loss: 0.3027 - accuracy: 0.8669\n",
      "Epoch 6/50\n",
      "166/166 [==============================] - 44s 267ms/step - loss: 0.2657 - accuracy: 0.8810\n",
      "Epoch 7/50\n",
      "166/166 [==============================] - 46s 278ms/step - loss: 0.2552 - accuracy: 0.8850\n",
      "Epoch 8/50\n",
      "166/166 [==============================] - 47s 283ms/step - loss: 0.2301 - accuracy: 0.9012\n",
      "Epoch 9/50\n",
      "166/166 [==============================] - 45s 273ms/step - loss: 0.2084 - accuracy: 0.9155\n",
      "Epoch 10/50\n",
      "166/166 [==============================] - 45s 273ms/step - loss: 0.1871 - accuracy: 0.9198\n",
      "Epoch 11/50\n",
      "166/166 [==============================] - 45s 270ms/step - loss: 0.1522 - accuracy: 0.9339\n",
      "Epoch 12/50\n",
      "166/166 [==============================] - 45s 272ms/step - loss: 0.1456 - accuracy: 0.9441\n",
      "Epoch 13/50\n",
      "166/166 [==============================] - 45s 272ms/step - loss: 0.1117 - accuracy: 0.9546\n",
      "Epoch 14/50\n",
      "166/166 [==============================] - 45s 272ms/step - loss: 0.0978 - accuracy: 0.9629\n",
      "Epoch 15/50\n",
      "166/166 [==============================] - 45s 274ms/step - loss: 0.0747 - accuracy: 0.9731\n",
      "Epoch 16/50\n",
      "166/166 [==============================] - 45s 272ms/step - loss: 0.0658 - accuracy: 0.9755\n",
      "Epoch 17/50\n",
      "166/166 [==============================] - 45s 268ms/step - loss: 0.0660 - accuracy: 0.9746\n",
      "Epoch 18/50\n",
      "166/166 [==============================] - 45s 270ms/step - loss: 0.0498 - accuracy: 0.9817\n",
      "Epoch 19/50\n",
      "166/166 [==============================] - 44s 268ms/step - loss: 0.0461 - accuracy: 0.9846\n",
      "Epoch 20/50\n",
      "166/166 [==============================] - 45s 269ms/step - loss: 0.0581 - accuracy: 0.9785\n",
      "Epoch 21/50\n",
      "166/166 [==============================] - 45s 271ms/step - loss: 0.0592 - accuracy: 0.9772\n",
      "Epoch 22/50\n",
      "166/166 [==============================] - 45s 269ms/step - loss: 0.0376 - accuracy: 0.9878\n",
      "Epoch 23/50\n",
      "166/166 [==============================] - 45s 271ms/step - loss: 0.0219 - accuracy: 0.9930\n",
      "Epoch 24/50\n",
      "166/166 [==============================] - 45s 270ms/step - loss: 0.0069 - accuracy: 0.9987\n",
      "Epoch 25/50\n",
      "166/166 [==============================] - 47s 280ms/step - loss: 0.0144 - accuracy: 0.9949\n",
      "Epoch 26/50\n",
      "166/166 [==============================] - 45s 273ms/step - loss: 0.0424 - accuracy: 0.9851\n",
      "Epoch 27/50\n",
      "166/166 [==============================] - 46s 276ms/step - loss: 0.0409 - accuracy: 0.9849\n",
      "Epoch 28/50\n",
      "166/166 [==============================] - 45s 272ms/step - loss: 0.0416 - accuracy: 0.9861\n",
      "Epoch 29/50\n",
      "166/166 [==============================] - 45s 273ms/step - loss: 0.0329 - accuracy: 0.9874\n",
      "Epoch 30/50\n",
      "166/166 [==============================] - 45s 272ms/step - loss: 0.0203 - accuracy: 0.9940\n",
      "Epoch 31/50\n",
      "166/166 [==============================] - 46s 274ms/step - loss: 0.0259 - accuracy: 0.9919\n",
      "Epoch 32/50\n",
      "166/166 [==============================] - 45s 272ms/step - loss: 0.0365 - accuracy: 0.9864\n",
      "Epoch 33/50\n",
      "166/166 [==============================] - 45s 270ms/step - loss: 0.0133 - accuracy: 0.9957\n",
      "Epoch 34/50\n",
      "166/166 [==============================] - 44s 268ms/step - loss: 0.0180 - accuracy: 0.9940\n",
      "Epoch 35/50\n",
      "166/166 [==============================] - 45s 269ms/step - loss: 0.0148 - accuracy: 0.9953\n",
      "Epoch 36/50\n",
      "166/166 [==============================] - 45s 271ms/step - loss: 0.0112 - accuracy: 0.9970\n",
      "Epoch 37/50\n",
      "166/166 [==============================] - 45s 268ms/step - loss: 0.0279 - accuracy: 0.9906\n",
      "Epoch 38/50\n",
      "166/166 [==============================] - 45s 270ms/step - loss: 0.0425 - accuracy: 0.9834\n",
      "Epoch 39/50\n",
      "166/166 [==============================] - 45s 269ms/step - loss: 0.0137 - accuracy: 0.9955\n",
      "Epoch 40/50\n",
      "166/166 [==============================] - 47s 282ms/step - loss: 0.0198 - accuracy: 0.9925\n",
      "Epoch 41/50\n",
      "166/166 [==============================] - 48s 290ms/step - loss: 0.0149 - accuracy: 0.9959\n",
      "Epoch 42/50\n",
      "166/166 [==============================] - 47s 284ms/step - loss: 0.0186 - accuracy: 0.9945\n",
      "Epoch 43/50\n",
      "166/166 [==============================] - 49s 297ms/step - loss: 0.0063 - accuracy: 0.9987\n",
      "Epoch 44/50\n",
      "166/166 [==============================] - 46s 279ms/step - loss: 0.0040 - accuracy: 0.9989\n",
      "Epoch 45/50\n",
      "166/166 [==============================] - 47s 283ms/step - loss: 0.0050 - accuracy: 0.9981\n",
      "Epoch 46/50\n",
      "166/166 [==============================] - 47s 281ms/step - loss: 0.0290 - accuracy: 0.9908\n",
      "Epoch 47/50\n",
      "166/166 [==============================] - 47s 285ms/step - loss: 0.0162 - accuracy: 0.9951\n",
      "Epoch 48/50\n",
      "166/166 [==============================] - 48s 288ms/step - loss: 0.0128 - accuracy: 0.9959\n",
      "Epoch 49/50\n",
      "166/166 [==============================] - 50s 299ms/step - loss: 0.0075 - accuracy: 0.9976\n",
      "Epoch 50/50\n",
      "166/166 [==============================] - 47s 283ms/step - loss: 0.0148 - accuracy: 0.9945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24cb6dac9a0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "model1.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model1.fit(train_generator, batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ad6ec3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 5s 117ms/step - loss: 1.5366 - accuracy: 0.8696\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = model1.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "274e6f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[685   0   0]\n",
      " [  0  95   0]\n",
      " [  0   0 547]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model1.predict(validation_generator)\n",
    "y_pred = np.argmax(pred, axis=1)\n",
    "y_true = np.argmax(pred, axis=1)\n",
    "print('confusion matrix')\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "    #confusion matrix\n",
    "f, ax = plt.subplots(figsize=(8,5))\n",
    "sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt=\".0f\", ax=ax)\n",
    "plt.xlabel(\"y_pred\")\n",
    "plt.ylabel(\"y_true\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f68710f",
   "metadata": {},
   "source": [
    "## Third CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6085eddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_52 (Conv2D)           (None, 63, 46, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 31, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 16, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 8, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 8, 6, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 4, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 128)               196736    \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 298,435\n",
      "Trainable params: 298,435\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = tf.keras.models.Sequential([\n",
    "    #first_convolution\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(128, 94, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    #second_convolution\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    #third_convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    #fourth_convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    #out ANN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax') \n",
    "]) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4cceca48",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "166/166 [==============================] - 40s 243ms/step - loss: 0.5435 - accuracy: 0.7639\n",
      "Epoch 2/50\n",
      "166/166 [==============================] - 38s 230ms/step - loss: 0.3931 - accuracy: 0.8268\n",
      "Epoch 3/50\n",
      "166/166 [==============================] - 39s 235ms/step - loss: 0.3627 - accuracy: 0.8436\n",
      "Epoch 4/50\n",
      "166/166 [==============================] - 38s 232ms/step - loss: 0.3325 - accuracy: 0.8605\n",
      "Epoch 5/50\n",
      "166/166 [==============================] - 39s 237ms/step - loss: 0.3144 - accuracy: 0.8658\n",
      "Epoch 6/50\n",
      "166/166 [==============================] - 40s 238ms/step - loss: 0.2938 - accuracy: 0.8737\n",
      "Epoch 7/50\n",
      "166/166 [==============================] - 39s 234ms/step - loss: 0.2875 - accuracy: 0.8735\n",
      "Epoch 8/50\n",
      "166/166 [==============================] - 42s 252ms/step - loss: 0.2694 - accuracy: 0.8827\n",
      "Epoch 9/50\n",
      "166/166 [==============================] - 40s 240ms/step - loss: 0.2552 - accuracy: 0.8887\n",
      "Epoch 10/50\n",
      "166/166 [==============================] - 39s 236ms/step - loss: 0.2449 - accuracy: 0.8946\n",
      "Epoch 11/50\n",
      "166/166 [==============================] - 39s 236ms/step - loss: 0.2330 - accuracy: 0.8993\n",
      "Epoch 12/50\n",
      "166/166 [==============================] - 39s 235ms/step - loss: 0.2232 - accuracy: 0.8998\n",
      "Epoch 13/50\n",
      "166/166 [==============================] - 38s 228ms/step - loss: 0.2124 - accuracy: 0.9046\n",
      "Epoch 14/50\n",
      "166/166 [==============================] - 38s 227ms/step - loss: 0.1994 - accuracy: 0.9115\n",
      "Epoch 15/50\n",
      "166/166 [==============================] - 39s 234ms/step - loss: 0.1926 - accuracy: 0.9138\n",
      "Epoch 16/50\n",
      "166/166 [==============================] - 38s 228ms/step - loss: 0.1749 - accuracy: 0.9213\n",
      "Epoch 17/50\n",
      "166/166 [==============================] - 37s 224ms/step - loss: 0.1753 - accuracy: 0.9275\n",
      "Epoch 18/50\n",
      "166/166 [==============================] - 39s 237ms/step - loss: 0.1571 - accuracy: 0.9317\n",
      "Epoch 19/50\n",
      "166/166 [==============================] - 39s 237ms/step - loss: 0.1453 - accuracy: 0.9379\n",
      "Epoch 20/50\n",
      "166/166 [==============================] - 42s 251ms/step - loss: 0.1336 - accuracy: 0.9424\n",
      "Epoch 21/50\n",
      "166/166 [==============================] - 38s 232ms/step - loss: 0.1281 - accuracy: 0.9450\n",
      "Epoch 22/50\n",
      "166/166 [==============================] - 38s 231ms/step - loss: 0.1265 - accuracy: 0.9482\n",
      "Epoch 23/50\n",
      "166/166 [==============================] - 39s 233ms/step - loss: 0.1096 - accuracy: 0.9561\n",
      "Epoch 24/50\n",
      "166/166 [==============================] - 38s 232ms/step - loss: 0.1038 - accuracy: 0.9605\n",
      "Epoch 25/50\n",
      "166/166 [==============================] - 38s 226ms/step - loss: 0.0982 - accuracy: 0.9601\n",
      "Epoch 26/50\n",
      "166/166 [==============================] - 38s 229ms/step - loss: 0.0873 - accuracy: 0.9646\n",
      "Epoch 27/50\n",
      "166/166 [==============================] - 38s 230ms/step - loss: 0.0850 - accuracy: 0.9686\n",
      "Epoch 28/50\n",
      "166/166 [==============================] - 38s 228ms/step - loss: 0.0758 - accuracy: 0.9697\n",
      "Epoch 29/50\n",
      "166/166 [==============================] - 38s 229ms/step - loss: 0.0784 - accuracy: 0.9678\n",
      "Epoch 30/50\n",
      "166/166 [==============================] - 38s 229ms/step - loss: 0.0677 - accuracy: 0.9740\n",
      "Epoch 31/50\n",
      "166/166 [==============================] - 38s 231ms/step - loss: 0.0566 - accuracy: 0.9787\n",
      "Epoch 32/50\n",
      "166/166 [==============================] - 37s 225ms/step - loss: 0.0599 - accuracy: 0.9763\n",
      "Epoch 33/50\n",
      "166/166 [==============================] - 37s 221ms/step - loss: 0.0625 - accuracy: 0.9780\n",
      "Epoch 34/50\n",
      "166/166 [==============================] - 37s 221ms/step - loss: 0.0550 - accuracy: 0.9795\n",
      "Epoch 35/50\n",
      "166/166 [==============================] - 37s 221ms/step - loss: 0.0567 - accuracy: 0.9772\n",
      "Epoch 36/50\n",
      "166/166 [==============================] - 36s 220ms/step - loss: 0.0515 - accuracy: 0.9808\n",
      "Epoch 37/50\n",
      "166/166 [==============================] - 36s 219ms/step - loss: 0.0460 - accuracy: 0.9838\n",
      "Epoch 38/50\n",
      "166/166 [==============================] - 37s 221ms/step - loss: 0.0604 - accuracy: 0.9746\n",
      "Epoch 39/50\n",
      "166/166 [==============================] - 37s 221ms/step - loss: 0.0420 - accuracy: 0.9853\n",
      "Epoch 40/50\n",
      "166/166 [==============================] - 37s 223ms/step - loss: 0.0395 - accuracy: 0.9851\n",
      "Epoch 41/50\n",
      "166/166 [==============================] - 37s 222ms/step - loss: 0.0404 - accuracy: 0.9849\n",
      "Epoch 42/50\n",
      "166/166 [==============================] - 36s 218ms/step - loss: 0.0600 - accuracy: 0.9797\n",
      "Epoch 43/50\n",
      "166/166 [==============================] - 37s 222ms/step - loss: 0.0361 - accuracy: 0.9863\n",
      "Epoch 44/50\n",
      "166/166 [==============================] - 37s 222ms/step - loss: 0.0366 - accuracy: 0.9866\n",
      "Epoch 45/50\n",
      "166/166 [==============================] - 36s 220ms/step - loss: 0.0488 - accuracy: 0.9827\n",
      "Epoch 46/50\n",
      "166/166 [==============================] - 37s 221ms/step - loss: 0.0273 - accuracy: 0.9902\n",
      "Epoch 47/50\n",
      "166/166 [==============================] - 37s 220ms/step - loss: 0.0348 - accuracy: 0.9870\n",
      "Epoch 48/50\n",
      "166/166 [==============================] - 37s 222ms/step - loss: 0.0330 - accuracy: 0.9887\n",
      "Epoch 49/50\n",
      "166/166 [==============================] - 37s 222ms/step - loss: 0.0412 - accuracy: 0.9863\n",
      "Epoch 50/50\n",
      "166/166 [==============================] - 37s 223ms/step - loss: 0.0340 - accuracy: 0.9900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24cb735c7f0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.001)\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model2.fit(train_generator, batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4626a819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 4s 106ms/step - loss: 1.0514 - accuracy: 0.8832\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = model2.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f47fa73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[713   0   0]\n",
      " [  0  74   0]\n",
      " [  0   0 540]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model2.predict(validation_generator)\n",
    "y_pred = np.argmax(pred, axis=1)\n",
    "y_true = np.argmax(pred, axis=1)\n",
    "print('confusion matrix')\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "    #confusion matrix\n",
    "f, ax = plt.subplots(figsize=(8,5))\n",
    "sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt=\".0f\", ax=ax)\n",
    "plt.xlabel(\"y_pred\")\n",
    "plt.ylabel(\"y_true\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0219ba78",
   "metadata": {},
   "source": [
    "# Prepare train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df04842e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>path</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>./Labelled/Bleatings/evt_000_000_000681_210415_150602.wav</th>\n",
       "      <td>Bleatings</td>\n",
       "      <td>0.347820</td>\n",
       "      <td>0.155233</td>\n",
       "      <td>-0.232169</td>\n",
       "      <td>-0.201178</td>\n",
       "      <td>0.206299</td>\n",
       "      <td>-0.812587</td>\n",
       "      <td>0.350786</td>\n",
       "      <td>-0.459605</td>\n",
       "      <td>-0.483644</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136273</td>\n",
       "      <td>-1.512237</td>\n",
       "      <td>0.313718</td>\n",
       "      <td>-0.025292</td>\n",
       "      <td>0.424550</td>\n",
       "      <td>0.618080</td>\n",
       "      <td>0.493849</td>\n",
       "      <td>-0.480913</td>\n",
       "      <td>0.115574</td>\n",
       "      <td>-0.861757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./Labelled/Bleatings/evt_000_000_000682_210415_150623.wav</th>\n",
       "      <td>Bleatings</td>\n",
       "      <td>0.600532</td>\n",
       "      <td>-0.009147</td>\n",
       "      <td>-0.807296</td>\n",
       "      <td>-0.633419</td>\n",
       "      <td>-0.555820</td>\n",
       "      <td>-0.483127</td>\n",
       "      <td>-0.247325</td>\n",
       "      <td>0.688479</td>\n",
       "      <td>1.102261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158165</td>\n",
       "      <td>-0.020859</td>\n",
       "      <td>0.099358</td>\n",
       "      <td>0.669381</td>\n",
       "      <td>-0.757209</td>\n",
       "      <td>0.146002</td>\n",
       "      <td>0.395391</td>\n",
       "      <td>0.874418</td>\n",
       "      <td>0.921241</td>\n",
       "      <td>0.427156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./Labelled/Bleatings/evt_000_000_000683_210415_150637.wav</th>\n",
       "      <td>Bleatings</td>\n",
       "      <td>0.146909</td>\n",
       "      <td>0.494060</td>\n",
       "      <td>-0.097277</td>\n",
       "      <td>0.017268</td>\n",
       "      <td>0.327210</td>\n",
       "      <td>0.516250</td>\n",
       "      <td>0.927306</td>\n",
       "      <td>-1.170098</td>\n",
       "      <td>0.393075</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.856356</td>\n",
       "      <td>-0.551477</td>\n",
       "      <td>-0.552312</td>\n",
       "      <td>0.002518</td>\n",
       "      <td>-0.085520</td>\n",
       "      <td>-0.047403</td>\n",
       "      <td>-0.229064</td>\n",
       "      <td>-0.437311</td>\n",
       "      <td>0.156396</td>\n",
       "      <td>-0.163401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./Labelled/Bleatings/evt_000_000_000684_210415_150654.wav</th>\n",
       "      <td>Bleatings</td>\n",
       "      <td>0.805780</td>\n",
       "      <td>0.976582</td>\n",
       "      <td>-0.477301</td>\n",
       "      <td>0.686392</td>\n",
       "      <td>-0.606207</td>\n",
       "      <td>-1.136907</td>\n",
       "      <td>-1.306880</td>\n",
       "      <td>-0.922357</td>\n",
       "      <td>-0.334283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>-1.164836</td>\n",
       "      <td>-0.138124</td>\n",
       "      <td>0.264209</td>\n",
       "      <td>-0.138784</td>\n",
       "      <td>0.276497</td>\n",
       "      <td>-0.528750</td>\n",
       "      <td>0.180946</td>\n",
       "      <td>0.164339</td>\n",
       "      <td>-0.217783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./Labelled/Bleatings/evt_000_000_002434_210416_073853.wav</th>\n",
       "      <td>Bleatings</td>\n",
       "      <td>0.651157</td>\n",
       "      <td>-0.002178</td>\n",
       "      <td>-0.902648</td>\n",
       "      <td>0.265438</td>\n",
       "      <td>-1.208112</td>\n",
       "      <td>-0.640320</td>\n",
       "      <td>-0.343720</td>\n",
       "      <td>1.102376</td>\n",
       "      <td>0.713345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.756449</td>\n",
       "      <td>0.452530</td>\n",
       "      <td>0.357011</td>\n",
       "      <td>0.359743</td>\n",
       "      <td>0.118464</td>\n",
       "      <td>0.318001</td>\n",
       "      <td>0.526162</td>\n",
       "      <td>0.199136</td>\n",
       "      <td>-0.190216</td>\n",
       "      <td>-0.760688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        label         0  \\\n",
       "path                                                                      \n",
       "./Labelled/Bleatings/evt_000_000_000681_210415_...  Bleatings  0.347820   \n",
       "./Labelled/Bleatings/evt_000_000_000682_210415_...  Bleatings  0.600532   \n",
       "./Labelled/Bleatings/evt_000_000_000683_210415_...  Bleatings  0.146909   \n",
       "./Labelled/Bleatings/evt_000_000_000684_210415_...  Bleatings  0.805780   \n",
       "./Labelled/Bleatings/evt_000_000_002434_210416_...  Bleatings  0.651157   \n",
       "\n",
       "                                                           1         2  \\\n",
       "path                                                                     \n",
       "./Labelled/Bleatings/evt_000_000_000681_210415_...  0.155233 -0.232169   \n",
       "./Labelled/Bleatings/evt_000_000_000682_210415_... -0.009147 -0.807296   \n",
       "./Labelled/Bleatings/evt_000_000_000683_210415_...  0.494060 -0.097277   \n",
       "./Labelled/Bleatings/evt_000_000_000684_210415_...  0.976582 -0.477301   \n",
       "./Labelled/Bleatings/evt_000_000_002434_210416_... -0.002178 -0.902648   \n",
       "\n",
       "                                                           3         4  \\\n",
       "path                                                                     \n",
       "./Labelled/Bleatings/evt_000_000_000681_210415_... -0.201178  0.206299   \n",
       "./Labelled/Bleatings/evt_000_000_000682_210415_... -0.633419 -0.555820   \n",
       "./Labelled/Bleatings/evt_000_000_000683_210415_...  0.017268  0.327210   \n",
       "./Labelled/Bleatings/evt_000_000_000684_210415_...  0.686392 -0.606207   \n",
       "./Labelled/Bleatings/evt_000_000_002434_210416_...  0.265438 -1.208112   \n",
       "\n",
       "                                                           5         6  \\\n",
       "path                                                                     \n",
       "./Labelled/Bleatings/evt_000_000_000681_210415_... -0.812587  0.350786   \n",
       "./Labelled/Bleatings/evt_000_000_000682_210415_... -0.483127 -0.247325   \n",
       "./Labelled/Bleatings/evt_000_000_000683_210415_...  0.516250  0.927306   \n",
       "./Labelled/Bleatings/evt_000_000_000684_210415_... -1.136907 -1.306880   \n",
       "./Labelled/Bleatings/evt_000_000_002434_210416_... -0.640320 -0.343720   \n",
       "\n",
       "                                                           7         8  ...  \\\n",
       "path                                                                    ...   \n",
       "./Labelled/Bleatings/evt_000_000_000681_210415_... -0.459605 -0.483644  ...   \n",
       "./Labelled/Bleatings/evt_000_000_000682_210415_...  0.688479  1.102261  ...   \n",
       "./Labelled/Bleatings/evt_000_000_000683_210415_... -1.170098  0.393075  ...   \n",
       "./Labelled/Bleatings/evt_000_000_000684_210415_... -0.922357 -0.334283  ...   \n",
       "./Labelled/Bleatings/evt_000_000_002434_210416_...  1.102376  0.713345  ...   \n",
       "\n",
       "                                                         190       191  \\\n",
       "path                                                                     \n",
       "./Labelled/Bleatings/evt_000_000_000681_210415_... -0.136273 -1.512237   \n",
       "./Labelled/Bleatings/evt_000_000_000682_210415_...  0.158165 -0.020859   \n",
       "./Labelled/Bleatings/evt_000_000_000683_210415_... -0.856356 -0.551477   \n",
       "./Labelled/Bleatings/evt_000_000_000684_210415_...  0.008805 -1.164836   \n",
       "./Labelled/Bleatings/evt_000_000_002434_210416_...  0.756449  0.452530   \n",
       "\n",
       "                                                         192       193  \\\n",
       "path                                                                     \n",
       "./Labelled/Bleatings/evt_000_000_000681_210415_...  0.313718 -0.025292   \n",
       "./Labelled/Bleatings/evt_000_000_000682_210415_...  0.099358  0.669381   \n",
       "./Labelled/Bleatings/evt_000_000_000683_210415_... -0.552312  0.002518   \n",
       "./Labelled/Bleatings/evt_000_000_000684_210415_... -0.138124  0.264209   \n",
       "./Labelled/Bleatings/evt_000_000_002434_210416_...  0.357011  0.359743   \n",
       "\n",
       "                                                         194       195  \\\n",
       "path                                                                     \n",
       "./Labelled/Bleatings/evt_000_000_000681_210415_...  0.424550  0.618080   \n",
       "./Labelled/Bleatings/evt_000_000_000682_210415_... -0.757209  0.146002   \n",
       "./Labelled/Bleatings/evt_000_000_000683_210415_... -0.085520 -0.047403   \n",
       "./Labelled/Bleatings/evt_000_000_000684_210415_... -0.138784  0.276497   \n",
       "./Labelled/Bleatings/evt_000_000_002434_210416_...  0.118464  0.318001   \n",
       "\n",
       "                                                         196       197  \\\n",
       "path                                                                     \n",
       "./Labelled/Bleatings/evt_000_000_000681_210415_...  0.493849 -0.480913   \n",
       "./Labelled/Bleatings/evt_000_000_000682_210415_...  0.395391  0.874418   \n",
       "./Labelled/Bleatings/evt_000_000_000683_210415_... -0.229064 -0.437311   \n",
       "./Labelled/Bleatings/evt_000_000_000684_210415_... -0.528750  0.180946   \n",
       "./Labelled/Bleatings/evt_000_000_002434_210416_...  0.526162  0.199136   \n",
       "\n",
       "                                                         198       199  \n",
       "path                                                                    \n",
       "./Labelled/Bleatings/evt_000_000_000681_210415_...  0.115574 -0.861757  \n",
       "./Labelled/Bleatings/evt_000_000_000682_210415_...  0.921241  0.427156  \n",
       "./Labelled/Bleatings/evt_000_000_000683_210415_...  0.156396 -0.163401  \n",
       "./Labelled/Bleatings/evt_000_000_000684_210415_...  0.164339 -0.217783  \n",
       "./Labelled/Bleatings/evt_000_000_002434_210416_... -0.190216 -0.760688  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv(\"sample.csv\", index_col=\"filename\")\n",
    "df = pd.read_csv(\"mfcc_deltamfcc.csv\", index_col=\"path\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a109e33",
   "metadata": {},
   "source": [
    "Extract and prepare the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "179e6c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = df[\"label\"]\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(label_list)#Scaling the Feature columns\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fc8f42",
   "metadata": {},
   "source": [
    "Extract and scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57baf1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>path</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>./Labelled/Bleatings/evt_000_000_000681_210415_150602.wav</th>\n",
       "      <td>Bleatings</td>\n",
       "      <td>0.347820</td>\n",
       "      <td>0.155233</td>\n",
       "      <td>-0.232169</td>\n",
       "      <td>-0.201178</td>\n",
       "      <td>0.206299</td>\n",
       "      <td>-0.812587</td>\n",
       "      <td>0.350786</td>\n",
       "      <td>-0.459605</td>\n",
       "      <td>-0.483644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404122</td>\n",
       "      <td>-0.136273</td>\n",
       "      <td>-1.512237</td>\n",
       "      <td>0.313718</td>\n",
       "      <td>-0.025292</td>\n",
       "      <td>0.424550</td>\n",
       "      <td>0.618080</td>\n",
       "      <td>0.493849</td>\n",
       "      <td>-0.480913</td>\n",
       "      <td>0.115574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./Labelled/Bleatings/evt_000_000_000682_210415_150623.wav</th>\n",
       "      <td>Bleatings</td>\n",
       "      <td>0.600532</td>\n",
       "      <td>-0.009147</td>\n",
       "      <td>-0.807296</td>\n",
       "      <td>-0.633419</td>\n",
       "      <td>-0.555820</td>\n",
       "      <td>-0.483127</td>\n",
       "      <td>-0.247325</td>\n",
       "      <td>0.688479</td>\n",
       "      <td>1.102261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.663562</td>\n",
       "      <td>0.158165</td>\n",
       "      <td>-0.020859</td>\n",
       "      <td>0.099358</td>\n",
       "      <td>0.669381</td>\n",
       "      <td>-0.757209</td>\n",
       "      <td>0.146002</td>\n",
       "      <td>0.395391</td>\n",
       "      <td>0.874418</td>\n",
       "      <td>0.921241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./Labelled/Bleatings/evt_000_000_000683_210415_150637.wav</th>\n",
       "      <td>Bleatings</td>\n",
       "      <td>0.146909</td>\n",
       "      <td>0.494060</td>\n",
       "      <td>-0.097277</td>\n",
       "      <td>0.017268</td>\n",
       "      <td>0.327210</td>\n",
       "      <td>0.516250</td>\n",
       "      <td>0.927306</td>\n",
       "      <td>-1.170098</td>\n",
       "      <td>0.393075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305720</td>\n",
       "      <td>-0.856356</td>\n",
       "      <td>-0.551477</td>\n",
       "      <td>-0.552312</td>\n",
       "      <td>0.002518</td>\n",
       "      <td>-0.085520</td>\n",
       "      <td>-0.047403</td>\n",
       "      <td>-0.229064</td>\n",
       "      <td>-0.437311</td>\n",
       "      <td>0.156396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./Labelled/Bleatings/evt_000_000_000684_210415_150654.wav</th>\n",
       "      <td>Bleatings</td>\n",
       "      <td>0.805780</td>\n",
       "      <td>0.976582</td>\n",
       "      <td>-0.477301</td>\n",
       "      <td>0.686392</td>\n",
       "      <td>-0.606207</td>\n",
       "      <td>-1.136907</td>\n",
       "      <td>-1.306880</td>\n",
       "      <td>-0.922357</td>\n",
       "      <td>-0.334283</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.506387</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>-1.164836</td>\n",
       "      <td>-0.138124</td>\n",
       "      <td>0.264209</td>\n",
       "      <td>-0.138784</td>\n",
       "      <td>0.276497</td>\n",
       "      <td>-0.528750</td>\n",
       "      <td>0.180946</td>\n",
       "      <td>0.164339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./Labelled/Bleatings/evt_000_000_002434_210416_073853.wav</th>\n",
       "      <td>Bleatings</td>\n",
       "      <td>0.651157</td>\n",
       "      <td>-0.002178</td>\n",
       "      <td>-0.902648</td>\n",
       "      <td>0.265438</td>\n",
       "      <td>-1.208112</td>\n",
       "      <td>-0.640320</td>\n",
       "      <td>-0.343720</td>\n",
       "      <td>1.102376</td>\n",
       "      <td>0.713345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275443</td>\n",
       "      <td>0.756449</td>\n",
       "      <td>0.452530</td>\n",
       "      <td>0.357011</td>\n",
       "      <td>0.359743</td>\n",
       "      <td>0.118464</td>\n",
       "      <td>0.318001</td>\n",
       "      <td>0.526162</td>\n",
       "      <td>0.199136</td>\n",
       "      <td>-0.190216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        label         0  \\\n",
       "path                                                                      \n",
       "./Labelled/Bleatings/evt_000_000_000681_210415_...  Bleatings  0.347820   \n",
       "./Labelled/Bleatings/evt_000_000_000682_210415_...  Bleatings  0.600532   \n",
       "./Labelled/Bleatings/evt_000_000_000683_210415_...  Bleatings  0.146909   \n",
       "./Labelled/Bleatings/evt_000_000_000684_210415_...  Bleatings  0.805780   \n",
       "./Labelled/Bleatings/evt_000_000_002434_210416_...  Bleatings  0.651157   \n",
       "\n",
       "                                                           1         2  \\\n",
       "path                                                                     \n",
       "./Labelled/Bleatings/evt_000_000_000681_210415_...  0.155233 -0.232169   \n",
       "./Labelled/Bleatings/evt_000_000_000682_210415_... -0.009147 -0.807296   \n",
       "./Labelled/Bleatings/evt_000_000_000683_210415_...  0.494060 -0.097277   \n",
       "./Labelled/Bleatings/evt_000_000_000684_210415_...  0.976582 -0.477301   \n",
       "./Labelled/Bleatings/evt_000_000_002434_210416_... -0.002178 -0.902648   \n",
       "\n",
       "                                                           3         4  \\\n",
       "path                                                                     \n",
       "./Labelled/Bleatings/evt_000_000_000681_210415_... -0.201178  0.206299   \n",
       "./Labelled/Bleatings/evt_000_000_000682_210415_... -0.633419 -0.555820   \n",
       "./Labelled/Bleatings/evt_000_000_000683_210415_...  0.017268  0.327210   \n",
       "./Labelled/Bleatings/evt_000_000_000684_210415_...  0.686392 -0.606207   \n",
       "./Labelled/Bleatings/evt_000_000_002434_210416_...  0.265438 -1.208112   \n",
       "\n",
       "                                                           5         6  \\\n",
       "path                                                                     \n",
       "./Labelled/Bleatings/evt_000_000_000681_210415_... -0.812587  0.350786   \n",
       "./Labelled/Bleatings/evt_000_000_000682_210415_... -0.483127 -0.247325   \n",
       "./Labelled/Bleatings/evt_000_000_000683_210415_...  0.516250  0.927306   \n",
       "./Labelled/Bleatings/evt_000_000_000684_210415_... -1.136907 -1.306880   \n",
       "./Labelled/Bleatings/evt_000_000_002434_210416_... -0.640320 -0.343720   \n",
       "\n",
       "                                                           7         8  ...  \\\n",
       "path                                                                    ...   \n",
       "./Labelled/Bleatings/evt_000_000_000681_210415_... -0.459605 -0.483644  ...   \n",
       "./Labelled/Bleatings/evt_000_000_000682_210415_...  0.688479  1.102261  ...   \n",
       "./Labelled/Bleatings/evt_000_000_000683_210415_... -1.170098  0.393075  ...   \n",
       "./Labelled/Bleatings/evt_000_000_000684_210415_... -0.922357 -0.334283  ...   \n",
       "./Labelled/Bleatings/evt_000_000_002434_210416_...  1.102376  0.713345  ...   \n",
       "\n",
       "                                                         189       190  \\\n",
       "path                                                                     \n",
       "./Labelled/Bleatings/evt_000_000_000681_210415_...  0.404122 -0.136273   \n",
       "./Labelled/Bleatings/evt_000_000_000682_210415_...  0.663562  0.158165   \n",
       "./Labelled/Bleatings/evt_000_000_000683_210415_...  0.305720 -0.856356   \n",
       "./Labelled/Bleatings/evt_000_000_000684_210415_... -0.506387  0.008805   \n",
       "./Labelled/Bleatings/evt_000_000_002434_210416_...  0.275443  0.756449   \n",
       "\n",
       "                                                         191       192  \\\n",
       "path                                                                     \n",
       "./Labelled/Bleatings/evt_000_000_000681_210415_... -1.512237  0.313718   \n",
       "./Labelled/Bleatings/evt_000_000_000682_210415_... -0.020859  0.099358   \n",
       "./Labelled/Bleatings/evt_000_000_000683_210415_... -0.551477 -0.552312   \n",
       "./Labelled/Bleatings/evt_000_000_000684_210415_... -1.164836 -0.138124   \n",
       "./Labelled/Bleatings/evt_000_000_002434_210416_...  0.452530  0.357011   \n",
       "\n",
       "                                                         193       194  \\\n",
       "path                                                                     \n",
       "./Labelled/Bleatings/evt_000_000_000681_210415_... -0.025292  0.424550   \n",
       "./Labelled/Bleatings/evt_000_000_000682_210415_...  0.669381 -0.757209   \n",
       "./Labelled/Bleatings/evt_000_000_000683_210415_...  0.002518 -0.085520   \n",
       "./Labelled/Bleatings/evt_000_000_000684_210415_...  0.264209 -0.138784   \n",
       "./Labelled/Bleatings/evt_000_000_002434_210416_...  0.359743  0.118464   \n",
       "\n",
       "                                                         195       196  \\\n",
       "path                                                                     \n",
       "./Labelled/Bleatings/evt_000_000_000681_210415_...  0.618080  0.493849   \n",
       "./Labelled/Bleatings/evt_000_000_000682_210415_...  0.146002  0.395391   \n",
       "./Labelled/Bleatings/evt_000_000_000683_210415_... -0.047403 -0.229064   \n",
       "./Labelled/Bleatings/evt_000_000_000684_210415_...  0.276497 -0.528750   \n",
       "./Labelled/Bleatings/evt_000_000_002434_210416_...  0.318001  0.526162   \n",
       "\n",
       "                                                         197       198  \n",
       "path                                                                    \n",
       "./Labelled/Bleatings/evt_000_000_000681_210415_... -0.480913  0.115574  \n",
       "./Labelled/Bleatings/evt_000_000_000682_210415_...  0.874418  0.921241  \n",
       "./Labelled/Bleatings/evt_000_000_000683_210415_... -0.437311  0.156396  \n",
       "./Labelled/Bleatings/evt_000_000_000684_210415_...  0.180946  0.164339  \n",
       "./Labelled/Bleatings/evt_000_000_002434_210416_...  0.199136 -0.190216  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.iloc[:, :-1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4d5bd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.34781968,  0.15523269, -0.23216898, ..., -0.480913  ,\n",
       "         0.11557389, -0.8617569 ],\n",
       "       [ 0.60053222, -0.00914684, -0.80729602, ...,  0.87441772,\n",
       "         0.92124129,  0.42715648],\n",
       "       [ 0.14690949,  0.49406041, -0.09727726, ..., -0.437311  ,\n",
       "         0.15639632, -0.1634006 ],\n",
       "       ...,\n",
       "       [-0.80134407,  0.67376678,  1.64300066, ...,  0.4749902 ,\n",
       "         0.44821466,  0.12015271],\n",
       "       [-1.06595033,  0.50232601,  1.30117149, ..., -0.23080317,\n",
       "        -0.31921245, -1.05481112],\n",
       "       [-1.28945793, -0.10242232,  1.45239209, ...,  0.51314051,\n",
       "        -1.91284518, -0.04138619]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scaler = StandardScaler()\n",
    "#X = scaler.fit_transform(np.array(df.iloc[:, :-1], dtype = float))#Dividing data into training and Testing set\n",
    "X = np.array(df.iloc[:,1:])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ecf224",
   "metadata": {},
   "source": [
    "And finally split in train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ab3a8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(661, 200), (166, 200), (661,), (166,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(f\"{np.shape(X_train)}, {np.shape(X_test)}, {np.shape(y_train)}, {np.shape(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8af476f",
   "metadata": {},
   "source": [
    "# Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae82b5e7",
   "metadata": {},
   "source": [
    "Let's build a simple ANN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eab2c007",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e6b8e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "67/67 [==============================] - 0s 955us/step - loss: 0.8344 - accuracy: 0.8533\n",
      "Epoch 2/100\n",
      "67/67 [==============================] - 0s 955us/step - loss: 0.1878 - accuracy: 0.9455\n",
      "Epoch 3/100\n",
      "67/67 [==============================] - 0s 881us/step - loss: 0.1050 - accuracy: 0.9758\n",
      "Epoch 4/100\n",
      "67/67 [==============================] - 0s 828us/step - loss: 0.0735 - accuracy: 0.9788\n",
      "Epoch 5/100\n",
      "67/67 [==============================] - 0s 898us/step - loss: 0.0513 - accuracy: 0.9879\n",
      "Epoch 6/100\n",
      "67/67 [==============================] - 0s 897us/step - loss: 0.0326 - accuracy: 0.9909\n",
      "Epoch 7/100\n",
      "67/67 [==============================] - 0s 814us/step - loss: 0.0247 - accuracy: 0.9939\n",
      "Epoch 8/100\n",
      "67/67 [==============================] - 0s 846us/step - loss: 0.0200 - accuracy: 0.9955\n",
      "Epoch 9/100\n",
      "67/67 [==============================] - 0s 830us/step - loss: 0.0169 - accuracy: 0.9970\n",
      "Epoch 10/100\n",
      "67/67 [==============================] - 0s 866us/step - loss: 0.0145 - accuracy: 0.9970\n",
      "Epoch 11/100\n",
      "67/67 [==============================] - 0s 868us/step - loss: 0.0133 - accuracy: 0.9970\n",
      "Epoch 12/100\n",
      "67/67 [==============================] - 0s 835us/step - loss: 0.0117 - accuracy: 0.9985\n",
      "Epoch 13/100\n",
      "67/67 [==============================] - 0s 925us/step - loss: 0.0103 - accuracy: 0.9985\n",
      "Epoch 14/100\n",
      "67/67 [==============================] - 0s 985us/step - loss: 0.0092 - accuracy: 0.9985\n",
      "Epoch 15/100\n",
      "67/67 [==============================] - 0s 940us/step - loss: 0.0090 - accuracy: 0.9985\n",
      "Epoch 16/100\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.0079 - accuracy: 0.9985\n",
      "Epoch 17/100\n",
      "67/67 [==============================] - 0s 881us/step - loss: 0.0072 - accuracy: 0.9985\n",
      "Epoch 18/100\n",
      "67/67 [==============================] - 0s 985us/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "67/67 [==============================] - 0s 1000us/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "67/67 [==============================] - 0s 881us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "67/67 [==============================] - 0s 881us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "67/67 [==============================] - 0s 895us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "67/67 [==============================] - 0s 911us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "67/67 [==============================] - 0s 940us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "67/67 [==============================] - 0s 836us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "67/67 [==============================] - 0s 866us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "67/67 [==============================] - 0s 896us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "67/67 [==============================] - 0s 806us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "67/67 [==============================] - 0s 836us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "67/67 [==============================] - 0s 925us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "67/67 [==============================] - 0s 836us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "67/67 [==============================] - 0s 836us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "67/67 [==============================] - 0s 896us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "67/67 [==============================] - 0s 806us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "67/67 [==============================] - 0s 881us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "67/67 [==============================] - 0s 791us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "67/67 [==============================] - 0s 866us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "67/67 [==============================] - 0s 821us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "67/67 [==============================] - 0s 881us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "67/67 [==============================] - 0s 806us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "67/67 [==============================] - 0s 776us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "67/67 [==============================] - 0s 881us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "67/67 [==============================] - 0s 851us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "67/67 [==============================] - 0s 895us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "67/67 [==============================] - 0s 896us/step - loss: 9.7123e-04 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "67/67 [==============================] - 0s 895us/step - loss: 9.2042e-04 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "67/67 [==============================] - 0s 881us/step - loss: 9.1908e-04 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "67/67 [==============================] - 0s 836us/step - loss: 8.3812e-04 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "67/67 [==============================] - 0s 791us/step - loss: 7.8469e-04 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "67/67 [==============================] - 0s 761us/step - loss: 7.2979e-04 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "67/67 [==============================] - 0s 851us/step - loss: 6.8571e-04 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "67/67 [==============================] - 0s 836us/step - loss: 6.5876e-04 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "67/67 [==============================] - 0s 836us/step - loss: 6.2864e-04 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "67/67 [==============================] - 0s 895us/step - loss: 6.0532e-04 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "67/67 [==============================] - 0s 821us/step - loss: 5.5662e-04 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "67/67 [==============================] - 0s 806us/step - loss: 5.3860e-04 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "67/67 [==============================] - 0s 836us/step - loss: 4.9864e-04 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "67/67 [==============================] - 0s 896us/step - loss: 4.7909e-04 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "67/67 [==============================] - 0s 911us/step - loss: 4.4581e-04 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "67/67 [==============================] - 0s 896us/step - loss: 4.2945e-04 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "67/67 [==============================] - 0s 836us/step - loss: 4.0966e-04 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "67/67 [==============================] - 0s 791us/step - loss: 3.8399e-04 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "67/67 [==============================] - 0s 836us/step - loss: 3.7269e-04 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "67/67 [==============================] - 0s 791us/step - loss: 3.4597e-04 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "67/67 [==============================] - 0s 866us/step - loss: 3.2820e-04 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "67/67 [==============================] - 0s 806us/step - loss: 3.1639e-04 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "67/67 [==============================] - 0s 896us/step - loss: 2.9326e-04 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "67/67 [==============================] - 0s 821us/step - loss: 2.8517e-04 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "67/67 [==============================] - 0s 836us/step - loss: 2.6448e-04 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "67/67 [==============================] - 0s 851us/step - loss: 2.5291e-04 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "67/67 [==============================] - 0s 821us/step - loss: 2.4808e-04 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "67/67 [==============================] - 0s 821us/step - loss: 2.3356e-04 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "67/67 [==============================] - 0s 791us/step - loss: 2.2557e-04 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "67/67 [==============================] - 0s 761us/step - loss: 2.0599e-04 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "67/67 [==============================] - 0s 896us/step - loss: 1.9985e-04 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "67/67 [==============================] - 0s 955us/step - loss: 1.9216e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "67/67 [==============================] - 0s 925us/step - loss: 1.8105e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "67/67 [==============================] - 0s 776us/step - loss: 1.7011e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 731us/step - loss: 1.6146e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "67/67 [==============================] - 0s 731us/step - loss: 1.5401e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "67/67 [==============================] - 0s 761us/step - loss: 1.4696e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "67/67 [==============================] - 0s 791us/step - loss: 1.4085e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "67/67 [==============================] - 0s 761us/step - loss: 1.3409e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "67/67 [==============================] - 0s 940us/step - loss: 1.2806e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "67/67 [==============================] - 0s 881us/step - loss: 1.2440e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "67/67 [==============================] - 0s 851us/step - loss: 1.1683e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "67/67 [==============================] - 0s 791us/step - loss: 1.1180e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "67/67 [==============================] - 0s 732us/step - loss: 1.0579e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "67/67 [==============================] - 0s 791us/step - loss: 1.0049e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "67/67 [==============================] - 0s 806us/step - loss: 9.6493e-05 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "67/67 [==============================] - 0s 791us/step - loss: 9.4147e-05 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "67/67 [==============================] - 0s 776us/step - loss: 8.7869e-05 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "67/67 [==============================] - 0s 806us/step - loss: 8.4791e-05 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "67/67 [==============================] - 0s 791us/step - loss: 8.0958e-05 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "67/67 [==============================] - 0s 851us/step - loss: 7.9335e-05 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "67/67 [==============================] - 0s 791us/step - loss: 7.4640e-05 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "67/67 [==============================] - 0s 836us/step - loss: 1.1378e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "67/67 [==============================] - 0s 821us/step - loss: 1.4555e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "67/67 [==============================] - 0s 821us/step - loss: 0.0148 - accuracy: 0.9985\n"
     ]
    }
   ],
   "source": [
    "classifier = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57c1b7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 766us/step - loss: 0.7015 - accuracy: 0.8855\n",
      "test loss, test acc: [0.701509416103363, 0.8855421543121338]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test, batch_size=10)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c2ee5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate predictions for 10 samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.44131846e-07, 4.31372655e-07, 9.99999404e-01],\n",
       "       [2.15698154e-10, 1.38699905e-08, 1.00000000e+00],\n",
       "       [6.96154628e-14, 5.07831312e-11, 1.00000000e+00],\n",
       "       [8.17135535e-03, 8.82230306e-05, 9.91740465e-01],\n",
       "       [9.77296694e-13, 8.40859968e-08, 9.99999881e-01],\n",
       "       [2.01135267e-21, 1.36356221e-15, 1.00000000e+00],\n",
       "       [9.99993682e-01, 3.68519295e-07, 5.92666174e-06],\n",
       "       [1.43916814e-11, 1.70348761e-13, 1.00000000e+00],\n",
       "       [8.61946940e-02, 2.24715180e-07, 9.13805068e-01],\n",
       "       [9.99989986e-01, 3.61334261e-11, 1.00424313e-05]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Generate predictions for 10 samples\")\n",
    "predictions = model.predict(X_test[:10])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93974df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 0, 2, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9b1d421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   real  predicted\n",
       "0     2          2\n",
       "1     2          2\n",
       "2     2          2\n",
       "3     2          2\n",
       "4     2          2\n",
       "5     2          2\n",
       "6     0          0\n",
       "7     2          2\n",
       "8     0          2\n",
       "9     0          0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real = y_test[:10]\n",
    "predicted = np.argmax(predictions, axis=1)\n",
    "pd.DataFrame(\n",
    "    {\"real\": real,\n",
    "     \"predicted\": predicted\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e9afca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
